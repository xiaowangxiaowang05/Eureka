task_name: ${task.name}
experiment: ''
env_path: ''
num_envs: ''
seed: 0
torch_deterministic: false
max_iterations: ''
physics_engine: physx
pipeline: gpu
sim_device: cuda:0
rl_device: cuda:0
graphics_device_id: 0
num_threads: 4
solver_type: 1
num_subscenes: 4
test: false
checkpoint: ''
sigma: ''
multi_gpu: false
wandb_activate: false
wandb_group: ''
wandb_name: ${train.params.config.name}
wandb_entity: ''
wandb_project: ''
wandb_tags: []
wandb_logcode_dir: ''
capture_video: false
capture_video_freq: 5000
capture_video_len: 200
force_render: false
headless: true
task:
  env:
    actionPenaltyScale: -0.0002
    actionsMovingAverage: 1.0
    aggregateMode: 1
    asset:
      assetFileName: mjcf/open_ai_assets/hand/shadow_hand.xml
      assetFileNameBlock: urdf/objects/cube_multicolor.urdf
      assetFileNameEgg: mjcf/open_ai_assets/hand/egg.xml
      assetFileNamePen: mjcf/open_ai_assets/hand/pen.xml
    asymmetric_observations: false
    clipActions: 1.0
    clipObservations: 5.0
    controlFrequencyInv: 1
    distRewardScale: -10.0
    dofSpeedScale: 20.0
    enableCameraSensors: false
    enableDebugVis: false
    envSpacing: 0.75
    env_name: shadow_handGPT
    episodeLength: 600
    fallDistance: 0.24
    fallPenalty: 0.0
    forceDecay: 0.99
    forceDecayInterval: 0.08
    forceLimitScale: 1.0
    forceProbRange:
    - 0.001
    - 0.1
    forceScale: 0.0
    maxConsecutiveSuccesses: 0
    numEnvs: ${resolve_default:10240,${...num_envs}}
    objectType: pen
    observationType: full_state
    printNumSuccesses: false
    reachGoalBonus: 250
    resetDofPosRandomInterval: 0.2
    resetDofVelRandomInterval: 0.0
    resetPositionNoise: 0.01
    resetRotationNoise: 0.0
    rotEps: 0.1
    rotRewardScale: 1.0
    startPositionNoise: 0.01
    startRotationNoise: 0.0
    stiffnessScale: 1.0
    successTolerance: 0.1
    useRelativeControl: false
  name: ShadowHandGPT
  physics_engine: ${..physics_engine}
  sim:
    dt: 0.01667
    gravity:
    - 0.0
    - 0.0
    - -9.81
    physx:
      bounce_threshold_velocity: 0.2
      contact_collection: 0
      contact_offset: 0.002
      default_buffer_size_multiplier: 5.0
      max_depenetration_velocity: 1000.0
      max_gpu_contact_pairs: 8388608
      num_position_iterations: 8
      num_subscenes: ${....num_subscenes}
      num_threads: ${....num_threads}
      num_velocity_iterations: 0
      rest_offset: 0.0
      solver_type: ${....solver_type}
      use_gpu: ${contains:"cuda",${....sim_device}}
    substeps: 2
    up_axis: z
    use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
  task:
    randomization_params:
      actions:
        distribution: gaussian
        operation: additive
        range:
        - 0.0
        - 0.05
        range_correlated:
        - 0
        - 0.015
      actor_params:
        hand:
          color: true
          dof_properties:
            damping:
              distribution: loguniform
              operation: scaling
              range:
              - 0.3
              - 3.0
            lower:
              distribution: gaussian
              operation: additive
              range:
              - 0
              - 0.01
            stiffness:
              distribution: loguniform
              operation: scaling
              range:
              - 0.75
              - 1.5
            upper:
              distribution: gaussian
              operation: additive
              range:
              - 0
              - 0.01
          rigid_body_properties:
            mass:
              distribution: uniform
              operation: scaling
              range:
              - 0.5
              - 1.5
              setup_only: true
          rigid_shape_properties:
            friction:
              distribution: uniform
              num_buckets: 250
              operation: scaling
              range:
              - 0.7
              - 1.3
          tendon_properties:
            damping:
              distribution: loguniform
              operation: scaling
              range:
              - 0.3
              - 3.0
            stiffness:
              distribution: loguniform
              operation: scaling
              range:
              - 0.75
              - 1.5
        object:
          rigid_body_properties:
            mass:
              distribution: uniform
              operation: scaling
              range:
              - 0.5
              - 1.5
              setup_only: true
          rigid_shape_properties:
            friction:
              distribution: uniform
              num_buckets: 250
              operation: scaling
              range:
              - 0.7
              - 1.3
          scale:
            distribution: uniform
            operation: scaling
            range:
            - 0.95
            - 1.05
            setup_only: true
      frequency: 720
      observations:
        distribution: gaussian
        operation: additive
        range:
        - 0
        - 0.002
        range_correlated:
        - 0
        - 0.001
      sim_params:
        gravity:
          distribution: gaussian
          operation: additive
          range:
          - 0
          - 0.4
    randomize: false
train:
  params:
    algo:
      name: a2c_continuous
    config:
      bounds_loss_coef: 0.0001
      clip_value: true
      critic_coef: 4
      e_clip: 0.2
      entropy_coef: 0.0
      env_name: rlgpu
      full_experiment_name: ${.name}
      gamma: 0.99
      grad_norm: 1.0
      horizon_length: 8
      kl_threshold: 0.016
      learning_rate: 0.0005
      lr_schedule: adaptive
      max_epochs: ${resolve_default:20000,${....max_iterations}}
      mini_epochs: 5
      minibatch_size: 10240
      mixed_precision: false
      multi_gpu: ${....multi_gpu}
      name: ${resolve_default:ShadowHandGPT,${....experiment}}
      normalize_advantage: true
      normalize_input: true
      normalize_value: true
      num_actors: ${....task.env.numEnvs}
      player:
        deterministic: true
        games_num: 2000
        print_stats: true
      ppo: true
      print_stats: true
      reward_shaper:
        scale_value: 0.01
      save_best_after: 100
      save_frequency: 200
      schedule_type: standard
      score_to_win: 100000
      seq_len: 4
      tau: 0.95
      truncate_grads: true
      value_bootstrap: true
    load_checkpoint: ${if:${...checkpoint},True,False}
    load_path: ${...checkpoint}
    model:
      name: continuous_a2c_logstd
    network:
      mlp:
        activation: elu
        d2rl: false
        initializer:
          name: default
        regularizer:
          name: None
        units:
        - 512
        - 512
        - 256
        - 128
      name: actor_critic
      separate: false
      space:
        continuous:
          fixed_sigma: true
          mu_activation: None
          mu_init:
            name: default
          sigma_activation: None
          sigma_init:
            name: const_initializer
            val: 0
    seed: ${...seed}
